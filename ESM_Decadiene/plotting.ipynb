{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for data processing and Visualizations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "## for statistical tests\n",
    "import scipy\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "## for machine learning\n",
    "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
    "## for explainer\n",
    "from lime import lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Data\n",
    "dtf = pd.read_csv('fitting.csv')\n",
    "\n",
    "#Assign Category Type\n",
    "dtf.astype('float64').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"LogKDW\"\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2,  sharex=False, sharey=False)\n",
    "fig.suptitle(x, fontsize=20)\n",
    "### distribution\n",
    "ax[0].title.set_text('distribution')\n",
    "variable = dtf[x].fillna(dtf[x].mean())\n",
    "breaks = np.quantile(variable, q=np.linspace(0, 1, 11))\n",
    "variable = variable[ (variable > breaks[0]) & (variable < \n",
    "                    breaks[10]) ]\n",
    "sns.distplot(variable, hist=True, kde=True, kde_kws={\"shade\": True}, ax=ax[0])\n",
    "des = dtf[x].describe()\n",
    "ax[0].axvline(des[\"25%\"], ls='--')\n",
    "ax[0].axvline(des[\"mean\"], ls='--')\n",
    "ax[0].axvline(des[\"75%\"], ls='--')\n",
    "ax[0].grid(True)\n",
    "des = round(des, 2).apply(lambda x: str(x))\n",
    "box = '\\n'.join((\"min: \"+des[\"min\"], \"25%: \"+des[\"25%\"], \"mean: \"+des[\"mean\"], \"75%: \"+des[\"75%\"], \"max: \"+des[\"max\"]))\n",
    "ax[0].text(0.95, 0.95, box, transform=ax[0].transAxes, fontsize=10, va='top', ha=\"right\", bbox=dict(boxstyle='round', facecolor='white', alpha=1))\n",
    "### boxplot \n",
    "ax[1].title.set_text('outliers (log scale)')\n",
    "tmp_dtf = pd.DataFrame(dtf[x])\n",
    "tmp_dtf[x] = np.log(tmp_dtf[x])\n",
    "tmp_dtf.boxplot(column=x, ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split data\n",
    "dtf_train, dtf_test = model_selection.train_test_split(dtf, \n",
    "                      test_size=0.3)\n",
    "## print info\n",
    "print(\"X_train shape:\", dtf_train.drop(\"LogKDW\",axis=1).shape, \"| X_test shape:\", dtf_test.drop(\"LogKDW\",axis=1).shape)\n",
    "print(\"y_train mean:\", round(np.mean(dtf_train[\"LogKDW\"]),2), \"| y_test mean:\", round(np.mean(dtf_test[\"LogKDW\"]),2))\n",
    "print(dtf_train.shape[1], \"features:\", dtf_train.drop(\"LogKDW\",axis=1).columns.to_list())\n",
    "\n",
    "\n",
    "corr_matrix = dtf_train.corr(method=\"pearson\")\n",
    "sns.heatmap(corr_matrix, vmin=-1., vmax=1., annot=True, fmt='.2f', cmap=\"YlGnBu\", cbar=True, linewidths=0.5)\n",
    "plt.title(\"pearson correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dtf_train.drop(\"LogKDW\", axis=1).values\n",
    "y = dtf_train[\"LogKDW\"].values\n",
    "feature_names = dtf_train.drop(\"LogKDW\", axis=1).columns.tolist()\n",
    "## call model\n",
    "model = ensemble.GradientBoostingRegressor()\n",
    "## Importance\n",
    "model.fit(X,y)\n",
    "importances = model.feature_importances_\n",
    "## Put in a pandas dtf\n",
    "dtf_importances = pd.DataFrame({\"IMPORTANCE\":importances, \n",
    "            \"VARIABLE\":feature_names}).sort_values(\"IMPORTANCE\", \n",
    "            ascending=False)\n",
    "dtf_importances[\"cumsum\"] =  dtf_importances['IMPORTANCE'].cumsum(axis=0)\n",
    "#cumsum =  dtf_importances['IMPORTANCE'].cumsum(axis=0)    \n",
    "dtf_importances = dtf_importances.set_index(\"VARIABLE\")\n",
    "    \n",
    "## Plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False)\n",
    "fig.suptitle(\"Features Importance\", fontsize=20)\n",
    "ax[0].title.set_text('variables')\n",
    "dtf_importances[[\"IMPORTANCE\"]].sort_values(by=\"IMPORTANCE\").plot(kind=\"barh\", legend=False, ax=ax[0]).grid(axis=\"x\")\n",
    "ax[0].set(ylabel=\"\")\n",
    "ax[1].title.set_text('cumulative')\n",
    "dtf_importances[[\"cumsum\"]].plot(kind=\"line\", linewidth=4, \n",
    "                                 legend=False, ax=ax[1])\n",
    "ax[1].set(xlabel=\"\", xticks=np.arange(len(dtf_importances)), \n",
    "          xticklabels=dtf_importances.index)\n",
    "plt.xticks(rotation=70)\n",
    "plt.grid(axis='both')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
